{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d107c28ba77e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-20 14:51:33.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /uufs/chpc.utah.edu/common/home/u1424875/research-projects/neural-feature-identification-pipeline/src\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/u1424875/research-projects/neural-feature-identification-pipeline/.venv/bin/python3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('vegafusion')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from neural_feature_identification.dataset_utils import generate_train_test_split\n",
    "\n",
    "print(sys.executable)\n",
    "alt.data_transformers.enable(\"vegafusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af729026f7aefd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:16.062801Z",
     "start_time": "2025-10-20T14:26:16.059004Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_project_config(config_path: Path) -> dict:\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57a9efbd8df5000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:17.697293Z",
     "start_time": "2025-10-20T14:26:17.691928Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_hdf_datasets(filepath: Path, keys: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Reads specified datasets from a single HDF5 file.\n",
    "    :param filepath:\n",
    "    :param keys:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"Warning File not found at {filepath}. Skipping.\")\n",
    "        return {}\n",
    "\n",
    "    data = {}\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        for key in keys:\n",
    "            if key in f:\n",
    "                data[key] = f[key][:]\n",
    "            else:\n",
    "                print(f\"Warning. Key '{key}' not found in {filepath.name}.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5bf042fed41503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:19.899899Z",
     "start_time": "2025-10-20T14:26:19.885778Z"
    }
   },
   "outputs": [],
   "source": [
    "def tidy_and_transform_data(session_data: dict, project_config: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Structures the data into a tidy, long-format DataFrame for VIS with Altair.\n",
    "    Transforms the data for VIS by downsampling and applying a normalization transformation to each channel.\n",
    "    :param project_config:\n",
    "    :param session_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Create initial nested DataFrame\n",
    "    df_constructor = {\n",
    "        'timestamps': all_data['kinematics']['nip_time'].T,\n",
    "        'kinematics': all_data['kinematics']['kinematics'].T,\n",
    "    }\n",
    "    feature_names = project_config['analysis']['feature_sets']\n",
    "    for name in feature_names:\n",
    "        key_name = name.lower()\n",
    "        if 'features' in session_data.get(key_name, {}):\n",
    "            df_constructor[name] = session_data[key_name]['features'].T\n",
    "    nested_df = pl.DataFrame(df_constructor)\n",
    "\n",
    "    # Flatten timestamp column\n",
    "    flat_df = nested_df.explode('timestamps')\n",
    "\n",
    "    # Dynamically create expression to unnest each array column into individual columns\n",
    "    unnested_expressions = []\n",
    "    for name in ['kinematics'] + feature_names:\n",
    "        col_name = name if name != 'kinematics' else 'kinematics'\n",
    "        if col_name in flat_df.columns:\n",
    "            list_len = flat_df.select(pl.col(col_name).arr.len().first()).item()\n",
    "            if list_len is not None:\n",
    "                unnested_expressions.extend(\n",
    "                    [pl.col(col_name).arr.get(i).alias(f\"{name}_{i+1}\") for i in range(list_len)]\n",
    "                )\n",
    "\n",
    "    # Build the wide DataFrame by applying the unnesting expressions\n",
    "    wide_df = flat_df.select(\n",
    "        pl.col('timestamps'),\n",
    "        *unnested_expressions\n",
    "    )\n",
    "\n",
    "    # Aggregate/downsample data to prevent browser memory issues\n",
    "    print(f\"Original data has {len(wide_df)} timestamps\")\n",
    "    plt_point_count = project_config['vis']['num_of_x_points']\n",
    "    time_range = wide_df['timestamps'].max() - wide_df['timestamps'].min()\n",
    "    resampling_interval = time_range / plt_point_count\n",
    "    if resampling_interval < 1: resampling_interval = 1\n",
    "    print(f\"Resampling data by averaging over {resampling_interval:0.2f} timestamp units\")\n",
    "    wide_df_resampled = wide_df.group_by(\n",
    "        (pl.col(\"timestamps\") // resampling_interval).alias(\"time_bin\")\n",
    "    ).agg(pl.all().mean()).drop(\"time_bin\")\n",
    "    print(f\"Resampled data has {len(wide_df_resampled)} timestamps\")\n",
    "\n",
    "    # Melt (wide2long/unpivot transform) the wide DataFrame into a long, tidy format\n",
    "    tidy_df = wide_df_resampled.unpivot(index=['timestamps'], variable_name='feature_id', value_name='value')\n",
    "\n",
    "    # Add a column for easy filtering ('feature_type': 'kinematics', 'nfr', ...)\n",
    "    tidy_df = tidy_df.with_columns(\n",
    "        pl.col('feature_id').str.split_exact(by='_', n=1).struct.field('field_0').alias('feature_type')\n",
    "    )\n",
    "\n",
    "    # Channel by channel normalization to improve heatmap visibility\n",
    "    kinematics_df  = tidy_df.filter(pl.col('feature_type') == 'kinematics')\n",
    "    features_df = tidy_df.filter(pl.col('feature_type') != 'kinematics')\n",
    "    features_df_normalized = features_df.with_columns(\n",
    "        min_val=pl.min('value').over('feature_id'),\n",
    "        max_val=pl.max('value').over('feature_id')\n",
    "    ).with_columns(\n",
    "        range_val=(pl.col('max_val') - pl.col('min_val'))\n",
    "    ).with_columns(\n",
    "        norm_val=pl.when(pl.col('range_val')>0)\n",
    "                 .then((pl.col('value') - pl.col('min_val')) / pl.col('range_val'))\n",
    "                 .otherwise(0.0)\n",
    "    ).with_columns(\n",
    "        value=(pl.col('norm_val') * pl.col('max_val').sqrt()).fill_nan(0)\n",
    "    ).drop('min_val', 'max_val', 'range_val', 'norm_val')\n",
    "    tidy_df_transformed = pl.concat([kinematics_df, features_df_normalized])\n",
    "\n",
    "    return tidy_df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ce4b9bcb8395e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:22.396115Z",
     "start_time": "2025-10-20T14:26:22.389151Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_kinematics_plot(plt_df: pl.DataFrame, project_config: dict, x_domain: list) -> alt.Chart():\n",
    "    \"\"\"\n",
    "    Creates a stacked line chart of the kinematic labels\n",
    "    :param plt_df:\n",
    "    :param project_config:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    kinematics_df = plt_df.filter(pl.col('feature_type') == 'kinematics')\n",
    "    plt_offset = project_config['vis']['kinematics_offset']\n",
    "    kinematics_df_offset = kinematics_df.with_columns(\n",
    "        pl.col('feature_id').str.split_exact(by='_', n=1).struct.field('field_1').cast(pl.Int32).alias('dof_id')\n",
    "    ).with_columns(\n",
    "        (pl.col('value') + (pl.col('dof_id')*plt_offset)).alias('plot_value')\n",
    "    )\n",
    "    plt_kinematics =  alt.Chart(kinematics_df_offset).mark_line().encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        y=alt.Y('plot_value:Q', title='Kinematic Position (Offset)', axis=alt.Axis(labels=False, ticks=False, grid=False)),\n",
    "        color=alt.Color('feature_id:N', title=\"DOF ID\", sort=alt.EncodingSortField(field='dof_id', order='descending')),\n",
    "    ).properties(\n",
    "        width=1800,\n",
    "        height=360,\n",
    "    )\n",
    "\n",
    "    return plt_kinematics\n",
    "\n",
    "def make_event_markers_plot(trial_start_stamps: np.ndarray, trial_stop_stamps: np.ndarray, x_domain: list) -> alt.Chart():\n",
    "    starts_df = pl.DataFrame({'timestamp': trial_start_stamps.flatten(), 'event': 'start'})\n",
    "    stops_df = pl.DataFrame({'timestamp': trial_stop_stamps.flatten(), 'event': 'stop'})\n",
    "    events_df = pl.concat([starts_df, stops_df])\n",
    "    plt_event_markers = alt.Chart(events_df).mark_rule(strokeDash=[4, 4], size=2).encode(\n",
    "        x=alt.X('timestamp:Q', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        color=alt.Color(\n",
    "            'event:N',\n",
    "            scale=alt.Scale(domain=['start', 'stop'], range=['green', 'red']),\n",
    "        )\n",
    "    ).properties(\n",
    "        width=1800,\n",
    "        height=36,\n",
    "    )\n",
    "\n",
    "\n",
    "    return plt_event_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a44973377246c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:24.702180Z",
     "start_time": "2025-10-20T14:26:24.694855Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_features_heatmap(plt_df: pl.DataFrame, feature_type: str, color_scheme: str, selected_chans: list[str] = None) -> alt.Chart:\n",
    "    feature_data = plt_df.filter(pl.col('feature_type') == feature_type)\n",
    "\n",
    "    if selected_chans:\n",
    "        feature_data = feature_data.filter(pl.col('feature_id').is_in(selected_chans))\n",
    "\n",
    "    return alt.Chart(feature_data).mark_rect().encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y('feature_id:O', title='Feature Index', sort=None, axis=alt.Axis(labels=False, ticks=False)),\n",
    "        detail='feature_id:N',\n",
    "    ).properties(\n",
    "        title=f'{feature_type.upper()} Features Vs NIP Time',\n",
    "        width=1800,\n",
    "        height=720\n",
    "    )\n",
    "\n",
    "def make_feature_line_plot(plt_df: pl.DataFrame, feature_type: str, selected_channels: list[str] = None, x_domain: list = None) -> alt.Chart:\n",
    "    \"\"\"\n",
    "    Create a line chart for a given feature set with superimposed, transparent channels\n",
    "    :param plt_df:\n",
    "    :param feature_type:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature_data = plt_df.filter(pl.col('feature_type') == feature_type)\n",
    "\n",
    "    # Apply subsampling if a list of selected channels is provided. Intended for the DWT feature set\n",
    "    if selected_channels:\n",
    "        feature_data = feature_data.filter(pl.col('feature_id').is_in(selected_channels))\n",
    "\n",
    "    return alt.Chart(feature_data).mark_line(opacity=0.12).encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        y=alt.Y('value:Q', title=f'{feature_type.upper()} Normalized Activation', axis=alt.Axis(labels=False, ticks=False,grid=False)),\n",
    "        detail='feature_id:N',\n",
    "    ).properties(width=1800, height=360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862319135938c293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:21.384073Z",
     "start_time": "2025-10-20T14:36:21.275950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 15.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "config = load_project_config(Path(\"../config.yaml\"))\n",
    "BASE_DIR = Path(\"/scratch/general/vast/u1424875/neural-feature-identification-pipeline/75\")#Path(\"C:/Users/f0397/Desktop/75\")\n",
    "\n",
    "files_to_load = {\n",
    "    'events': {'path': BASE_DIR / \"events.h5\", 'keys': ['trial_start_idxs', 'trial_stop_idxs']},\n",
    "    'kinematics': {'path': BASE_DIR / \"kinematics.h5\", 'keys': ['kinematics', 'nip_time']},\n",
    "}\n",
    "for feature_name in config['analysis']['feature_sets']:\n",
    "    key_name = feature_name.lower()\n",
    "    files_to_load[key_name] = {'path': BASE_DIR / \"features\" / f\"{feature_name}.h5\", 'keys': ['features']}\n",
    "\n",
    "all_data = {}\n",
    "for name, details in tqdm(files_to_load.items(), desc='Loading data files'):\n",
    "    all_data[name] = read_hdf_datasets(details['path'], details['keys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257c4819fb4d590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 13586 timestamps\n",
      "Resampling data by averaging over 20384.84 timestamp units\n",
      "Resampled data has 661 timestamps\n",
      "shape: (5,)\n",
      "Series: 'feature_type' [str]\n",
      "[\n",
      "\t\"kinematics\"\n",
      "\t\"DWT-DB4\"\n",
      "\t\"MAV\"\n",
      "\t\"SBP-RAW\"\n",
      "\t\"NFR\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_657_788, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamps</th><th>feature_id</th><th>value</th><th>feature_type</th></tr><tr><td>f64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>3.9149e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>4.0617e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>3.9720e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>4.2043801e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>4.1452e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3.6254e7</td><td>&quot;MAV_192&quot;</td><td>0.114731</td><td>&quot;MAV&quot;</td></tr><tr><td>3.3299e7</td><td>&quot;MAV_192&quot;</td><td>0.319108</td><td>&quot;MAV&quot;</td></tr><tr><td>3.9394e7</td><td>&quot;MAV_192&quot;</td><td>0.326147</td><td>&quot;MAV&quot;</td></tr><tr><td>4.4144e7</td><td>&quot;MAV_192&quot;</td><td>0.637485</td><td>&quot;MAV&quot;</td></tr><tr><td>3.3237e7</td><td>&quot;MAV_192&quot;</td><td>0.242935</td><td>&quot;MAV&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_657_788, 4)\n",
       "┌─────────────┬──────────────┬──────────┬──────────────┐\n",
       "│ timestamps  ┆ feature_id   ┆ value    ┆ feature_type │\n",
       "│ ---         ┆ ---          ┆ ---      ┆ ---          │\n",
       "│ f64         ┆ str          ┆ f64      ┆ str          │\n",
       "╞═════════════╪══════════════╪══════════╪══════════════╡\n",
       "│ 3.9149e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 4.0617e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 3.9720e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 4.2043801e7 ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 4.1452e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ …           ┆ …            ┆ …        ┆ …            │\n",
       "│ 3.6254e7    ┆ MAV_192      ┆ 0.114731 ┆ MAV          │\n",
       "│ 3.3299e7    ┆ MAV_192      ┆ 0.319108 ┆ MAV          │\n",
       "│ 3.9394e7    ┆ MAV_192      ┆ 0.326147 ┆ MAV          │\n",
       "│ 4.4144e7    ┆ MAV_192      ┆ 0.637485 ┆ MAV          │\n",
       "│ 3.3237e7    ┆ MAV_192      ┆ 0.242935 ┆ MAV          │\n",
       "└─────────────┴──────────────┴──────────┴──────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_df = tidy_and_transform_data(all_data, config)\n",
    "print(tidy_df['feature_type'].unique())\n",
    "tidy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eee72225b64c99d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.517122Z",
     "start_time": "2025-10-20T03:58:24.480252Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "selected_channels_map = {}\n",
    "dwt_subsample_count = config['vis']['dwt_subsample_count']\n",
    "dwt_df = tidy_df.filter(pl.col('feature_type') == 'DWT-DB4')\n",
    "all_dwt_channels = dwt_df.get_column('feature_id').unique().to_list()\n",
    "if len(all_dwt_channels) > dwt_subsample_count:\n",
    "    selected_channels_map['dwt-db4'] = random.sample(all_dwt_channels, dwt_subsample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3002e213bee035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.527582Z",
     "start_time": "2025-10-20T03:58:24.523071Z"
    }
   },
   "outputs": [],
   "source": [
    "start_stamps = all_data.get('events', {}).get('trial_start_idxs', np.array([]))\n",
    "stop_stamps = all_data.get('events', {}).get('trial_stop_idxs', np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ba2d236acbac9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.546174Z",
     "start_time": "2025-10-20T03:58:24.537716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31978596.6, 45423141.45454545]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_domain = [tidy_df['timestamps'].min(), tidy_df['timestamps'].max()]\n",
    "x_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dac3d8dd84a89c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.631839Z",
     "start_time": "2025-10-20T03:58:24.577293Z"
    }
   },
   "outputs": [],
   "source": [
    "plt_kinematics = make_kinematics_plot(tidy_df, config, x_domain=x_domain)\n",
    "plt_events = make_event_markers_plot(start_stamps, stop_stamps, x_domain=x_domain)\n",
    "plt_features = []\n",
    "for f_name in config['analysis']['feature_sets']:\n",
    "    feature_key = f_name.lower()\n",
    "    selected_channels = selected_channels_map.get(feature_key)\n",
    "    plt = make_feature_line_plot(tidy_df, f_name, selected_channels, x_domain=x_domain)\n",
    "    plt_features.append(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b411a7c7f0d7aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.648890Z",
     "start_time": "2025-10-20T03:58:24.639106Z"
    }
   },
   "outputs": [],
   "source": [
    "final_chart = alt.vconcat(\n",
    "    plt_kinematics,\n",
    "    plt_events,\n",
    "    *plt_features,\n",
    ").resolve_scale(\n",
    "    color='independent',\n",
    ").properties(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925074c31d3996a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chart.save(\"session_vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94da2c90-3a00-41ac-ac55-4bc0f1208b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:26.734685Z",
     "start_time": "2025-10-20T14:36:26.730158Z"
    }
   },
   "outputs": [],
   "source": [
    "kinematics_data = all_data['kinematics']['kinematics'].T\n",
    "timestamps_vec = all_data['kinematics']['nip_time'].T\n",
    "start_stamps = all_data['events']['trial_start_idxs'].T\n",
    "stop_stamps = all_data['events']['trial_stop_idxs'].T\n",
    "split_params = config['analysis']['train_test_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82921c1263d15da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:26.734685Z",
     "start_time": "2025-10-20T14:36:26.730158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(12, 13586))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinematics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b248890-5727-4550-ae93-bb72c2202dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:37.028246Z",
     "start_time": "2025-10-20T14:36:37.022141Z"
    }
   },
   "outputs": [],
   "source": [
    "train_idxs, test_idxs, train_trials_info, test_trials_info =  generate_train_test_split(\n",
    "    kinematics=kinematics_data,\n",
    "    kinematics_timestamps=timestamps_vec,\n",
    "    trial_start_timestamps=start_stamps,\n",
    "    trial_stop_timestamps=stop_stamps,\n",
    "    train_ratio=split_params['train_ratio'],\n",
    "    training_type=split_params['split_type'],\n",
    "    include_combined=split_params['include_combined'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b7c6a876222b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:37.028246Z",
     "start_time": "2025-10-20T14:36:37.022141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(34),\n",
       "  'stop_idx': np.int64(97),\n",
       "  'relative_start_idx': 0,\n",
       "  'relative_stop_idx': np.int64(63)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(128),\n",
       "  'stop_idx': np.int64(191),\n",
       "  'relative_start_idx': np.int64(63),\n",
       "  'relative_stop_idx': np.int64(126)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(222),\n",
       "  'stop_idx': np.int64(284),\n",
       "  'relative_start_idx': np.int64(126),\n",
       "  'relative_stop_idx': np.int64(188)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(315),\n",
       "  'stop_idx': np.int64(377),\n",
       "  'relative_start_idx': np.int64(188),\n",
       "  'relative_stop_idx': np.int64(250)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(408),\n",
       "  'stop_idx': np.int64(471),\n",
       "  'relative_start_idx': np.int64(250),\n",
       "  'relative_stop_idx': np.int64(313)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(502),\n",
       "  'stop_idx': np.int64(564),\n",
       "  'relative_start_idx': np.int64(313),\n",
       "  'relative_stop_idx': np.int64(375)},\n",
       " {'gesture_id': 'dof_1_pos',\n",
       "  'start_idx': np.int64(595),\n",
       "  'stop_idx': np.int64(657),\n",
       "  'relative_start_idx': np.int64(375),\n",
       "  'relative_stop_idx': np.int64(437)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(998),\n",
       "  'stop_idx': np.int64(1061),\n",
       "  'relative_start_idx': np.int64(437),\n",
       "  'relative_stop_idx': np.int64(500)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1092),\n",
       "  'stop_idx': np.int64(1154),\n",
       "  'relative_start_idx': np.int64(500),\n",
       "  'relative_stop_idx': np.int64(562)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1185),\n",
       "  'stop_idx': np.int64(1247),\n",
       "  'relative_start_idx': np.int64(562),\n",
       "  'relative_stop_idx': np.int64(624)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1279),\n",
       "  'stop_idx': np.int64(1341),\n",
       "  'relative_start_idx': np.int64(624),\n",
       "  'relative_stop_idx': np.int64(686)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1372),\n",
       "  'stop_idx': np.int64(1434),\n",
       "  'relative_start_idx': np.int64(686),\n",
       "  'relative_stop_idx': np.int64(748)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1466),\n",
       "  'stop_idx': np.int64(1527),\n",
       "  'relative_start_idx': np.int64(748),\n",
       "  'relative_stop_idx': np.int64(809)},\n",
       " {'gesture_id': 'dof_2_pos',\n",
       "  'start_idx': np.int64(1558),\n",
       "  'stop_idx': np.int64(1621),\n",
       "  'relative_start_idx': np.int64(809),\n",
       "  'relative_stop_idx': np.int64(872)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(1964),\n",
       "  'stop_idx': np.int64(2026),\n",
       "  'relative_start_idx': np.int64(872),\n",
       "  'relative_stop_idx': np.int64(934)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2057),\n",
       "  'stop_idx': np.int64(2120),\n",
       "  'relative_start_idx': np.int64(934),\n",
       "  'relative_stop_idx': np.int64(997)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2151),\n",
       "  'stop_idx': np.int64(2213),\n",
       "  'relative_start_idx': np.int64(997),\n",
       "  'relative_stop_idx': np.int64(1059)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2244),\n",
       "  'stop_idx': np.int64(2307),\n",
       "  'relative_start_idx': np.int64(1059),\n",
       "  'relative_stop_idx': np.int64(1122)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2337),\n",
       "  'stop_idx': np.int64(2400),\n",
       "  'relative_start_idx': np.int64(1122),\n",
       "  'relative_stop_idx': np.int64(1185)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2431),\n",
       "  'stop_idx': np.int64(2493),\n",
       "  'relative_start_idx': np.int64(1185),\n",
       "  'relative_stop_idx': np.int64(1247)},\n",
       " {'gesture_id': 'dof_3_pos',\n",
       "  'start_idx': np.int64(2524),\n",
       "  'stop_idx': np.int64(2586),\n",
       "  'relative_start_idx': np.int64(1247),\n",
       "  'relative_stop_idx': np.int64(1309)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(2928),\n",
       "  'stop_idx': np.int64(2990),\n",
       "  'relative_start_idx': np.int64(1309),\n",
       "  'relative_stop_idx': np.int64(1371)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3021),\n",
       "  'stop_idx': np.int64(3083),\n",
       "  'relative_start_idx': np.int64(1371),\n",
       "  'relative_stop_idx': np.int64(1433)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3114),\n",
       "  'stop_idx': np.int64(3176),\n",
       "  'relative_start_idx': np.int64(1433),\n",
       "  'relative_stop_idx': np.int64(1495)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3208),\n",
       "  'stop_idx': np.int64(3270),\n",
       "  'relative_start_idx': np.int64(1495),\n",
       "  'relative_stop_idx': np.int64(1557)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3301),\n",
       "  'stop_idx': np.int64(3364),\n",
       "  'relative_start_idx': np.int64(1557),\n",
       "  'relative_stop_idx': np.int64(1620)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3394),\n",
       "  'stop_idx': np.int64(3456),\n",
       "  'relative_start_idx': np.int64(1620),\n",
       "  'relative_stop_idx': np.int64(1682)},\n",
       " {'gesture_id': 'dof_1_neg',\n",
       "  'start_idx': np.int64(3488),\n",
       "  'stop_idx': np.int64(3550),\n",
       "  'relative_start_idx': np.int64(1682),\n",
       "  'relative_stop_idx': np.int64(1744)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(3893),\n",
       "  'stop_idx': np.int64(3955),\n",
       "  'relative_start_idx': np.int64(1744),\n",
       "  'relative_stop_idx': np.int64(1806)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(3986),\n",
       "  'stop_idx': np.int64(4048),\n",
       "  'relative_start_idx': np.int64(1806),\n",
       "  'relative_stop_idx': np.int64(1868)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(4080),\n",
       "  'stop_idx': np.int64(4142),\n",
       "  'relative_start_idx': np.int64(1868),\n",
       "  'relative_stop_idx': np.int64(1930)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(4173),\n",
       "  'stop_idx': np.int64(4235),\n",
       "  'relative_start_idx': np.int64(1930),\n",
       "  'relative_stop_idx': np.int64(1992)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(4266),\n",
       "  'stop_idx': np.int64(4328),\n",
       "  'relative_start_idx': np.int64(1992),\n",
       "  'relative_stop_idx': np.int64(2054)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(4360),\n",
       "  'stop_idx': np.int64(4422),\n",
       "  'relative_start_idx': np.int64(2054),\n",
       "  'relative_stop_idx': np.int64(2116)},\n",
       " {'gesture_id': 'dof_2_neg',\n",
       "  'start_idx': np.int64(4453),\n",
       "  'stop_idx': np.int64(4515),\n",
       "  'relative_start_idx': np.int64(2116),\n",
       "  'relative_stop_idx': np.int64(2178)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(4856),\n",
       "  'stop_idx': np.int64(4925),\n",
       "  'relative_start_idx': np.int64(2178),\n",
       "  'relative_stop_idx': np.int64(2247)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(4956),\n",
       "  'stop_idx': np.int64(5024),\n",
       "  'relative_start_idx': np.int64(2247),\n",
       "  'relative_stop_idx': np.int64(2315)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(5055),\n",
       "  'stop_idx': np.int64(5123),\n",
       "  'relative_start_idx': np.int64(2315),\n",
       "  'relative_stop_idx': np.int64(2383)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(5155),\n",
       "  'stop_idx': np.int64(5223),\n",
       "  'relative_start_idx': np.int64(2383),\n",
       "  'relative_stop_idx': np.int64(2451)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(5254),\n",
       "  'stop_idx': np.int64(5322),\n",
       "  'relative_start_idx': np.int64(2451),\n",
       "  'relative_stop_idx': np.int64(2519)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(5353),\n",
       "  'stop_idx': np.int64(5423),\n",
       "  'relative_start_idx': np.int64(2519),\n",
       "  'relative_stop_idx': np.int64(2589)},\n",
       " {'gesture_id': 'dof_3_neg',\n",
       "  'start_idx': np.int64(5453),\n",
       "  'stop_idx': np.int64(5522),\n",
       "  'relative_start_idx': np.int64(2589),\n",
       "  'relative_stop_idx': np.int64(2658)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(5883),\n",
       "  'stop_idx': np.int64(5945),\n",
       "  'relative_start_idx': np.int64(2658),\n",
       "  'relative_stop_idx': np.int64(2720)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(5976),\n",
       "  'stop_idx': np.int64(6038),\n",
       "  'relative_start_idx': np.int64(2720),\n",
       "  'relative_stop_idx': np.int64(2782)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(6070),\n",
       "  'stop_idx': np.int64(6132),\n",
       "  'relative_start_idx': np.int64(2782),\n",
       "  'relative_stop_idx': np.int64(2844)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(6163),\n",
       "  'stop_idx': np.int64(6225),\n",
       "  'relative_start_idx': np.int64(2844),\n",
       "  'relative_stop_idx': np.int64(2906)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(6257),\n",
       "  'stop_idx': np.int64(6319),\n",
       "  'relative_start_idx': np.int64(2906),\n",
       "  'relative_stop_idx': np.int64(2968)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(6350),\n",
       "  'stop_idx': np.int64(6412),\n",
       "  'relative_start_idx': np.int64(2968),\n",
       "  'relative_stop_idx': np.int64(3030)},\n",
       " {'gesture_id': 'dof_6_pos',\n",
       "  'start_idx': np.int64(6443),\n",
       "  'stop_idx': np.int64(6506),\n",
       "  'relative_start_idx': np.int64(3030),\n",
       "  'relative_stop_idx': np.int64(3093)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(6847),\n",
       "  'stop_idx': np.int64(6909),\n",
       "  'relative_start_idx': np.int64(3093),\n",
       "  'relative_stop_idx': np.int64(3155)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(6940),\n",
       "  'stop_idx': np.int64(7002),\n",
       "  'relative_start_idx': np.int64(3155),\n",
       "  'relative_stop_idx': np.int64(3217)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(7033),\n",
       "  'stop_idx': np.int64(7096),\n",
       "  'relative_start_idx': np.int64(3217),\n",
       "  'relative_stop_idx': np.int64(3280)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(7127),\n",
       "  'stop_idx': np.int64(7189),\n",
       "  'relative_start_idx': np.int64(3280),\n",
       "  'relative_stop_idx': np.int64(3342)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(7220),\n",
       "  'stop_idx': np.int64(7282),\n",
       "  'relative_start_idx': np.int64(3342),\n",
       "  'relative_stop_idx': np.int64(3404)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(7314),\n",
       "  'stop_idx': np.int64(7377),\n",
       "  'relative_start_idx': np.int64(3404),\n",
       "  'relative_stop_idx': np.int64(3467)},\n",
       " {'gesture_id': 'dof_6_neg',\n",
       "  'start_idx': np.int64(7408),\n",
       "  'stop_idx': np.int64(7470),\n",
       "  'relative_start_idx': np.int64(3467),\n",
       "  'relative_stop_idx': np.int64(3529)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(7812),\n",
       "  'stop_idx': np.int64(7874),\n",
       "  'relative_start_idx': np.int64(3529),\n",
       "  'relative_stop_idx': np.int64(3591)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(7905),\n",
       "  'stop_idx': np.int64(7968),\n",
       "  'relative_start_idx': np.int64(3591),\n",
       "  'relative_stop_idx': np.int64(3654)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(7998),\n",
       "  'stop_idx': np.int64(8060),\n",
       "  'relative_start_idx': np.int64(3654),\n",
       "  'relative_stop_idx': np.int64(3716)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(8092),\n",
       "  'stop_idx': np.int64(8154),\n",
       "  'relative_start_idx': np.int64(3716),\n",
       "  'relative_stop_idx': np.int64(3778)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(8185),\n",
       "  'stop_idx': np.int64(8247),\n",
       "  'relative_start_idx': np.int64(3778),\n",
       "  'relative_stop_idx': np.int64(3840)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(8278),\n",
       "  'stop_idx': np.int64(8340),\n",
       "  'relative_start_idx': np.int64(3840),\n",
       "  'relative_stop_idx': np.int64(3902)},\n",
       " {'gesture_id': 'dof_10_pos',\n",
       "  'start_idx': np.int64(8372),\n",
       "  'stop_idx': np.int64(8434),\n",
       "  'relative_start_idx': np.int64(3902),\n",
       "  'relative_stop_idx': np.int64(3964)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(8775),\n",
       "  'stop_idx': np.int64(8838),\n",
       "  'relative_start_idx': np.int64(3964),\n",
       "  'relative_stop_idx': np.int64(4027)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(8869),\n",
       "  'stop_idx': np.int64(8931),\n",
       "  'relative_start_idx': np.int64(4027),\n",
       "  'relative_stop_idx': np.int64(4089)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(8962),\n",
       "  'stop_idx': np.int64(9024),\n",
       "  'relative_start_idx': np.int64(4089),\n",
       "  'relative_stop_idx': np.int64(4151)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(9055),\n",
       "  'stop_idx': np.int64(9118),\n",
       "  'relative_start_idx': np.int64(4151),\n",
       "  'relative_stop_idx': np.int64(4214)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(9150),\n",
       "  'stop_idx': np.int64(9212),\n",
       "  'relative_start_idx': np.int64(4214),\n",
       "  'relative_stop_idx': np.int64(4276)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(9244),\n",
       "  'stop_idx': np.int64(9306),\n",
       "  'relative_start_idx': np.int64(4276),\n",
       "  'relative_stop_idx': np.int64(4338)},\n",
       " {'gesture_id': 'dof_10_neg',\n",
       "  'start_idx': np.int64(9337),\n",
       "  'stop_idx': np.int64(9399),\n",
       "  'relative_start_idx': np.int64(4338),\n",
       "  'relative_stop_idx': np.int64(4400)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(9741),\n",
       "  'stop_idx': np.int64(9803),\n",
       "  'relative_start_idx': np.int64(4400),\n",
       "  'relative_stop_idx': np.int64(4462)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(9834),\n",
       "  'stop_idx': np.int64(9897),\n",
       "  'relative_start_idx': np.int64(4462),\n",
       "  'relative_stop_idx': np.int64(4525)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(9928),\n",
       "  'stop_idx': np.int64(9990),\n",
       "  'relative_start_idx': np.int64(4525),\n",
       "  'relative_stop_idx': np.int64(4587)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(10021),\n",
       "  'stop_idx': np.int64(10083),\n",
       "  'relative_start_idx': np.int64(4587),\n",
       "  'relative_stop_idx': np.int64(4649)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(10114),\n",
       "  'stop_idx': np.int64(10177),\n",
       "  'relative_start_idx': np.int64(4649),\n",
       "  'relative_stop_idx': np.int64(4712)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(10208),\n",
       "  'stop_idx': np.int64(10270),\n",
       "  'relative_start_idx': np.int64(4712),\n",
       "  'relative_stop_idx': np.int64(4774)},\n",
       " {'gesture_id': 'dof_12_pos',\n",
       "  'start_idx': np.int64(10301),\n",
       "  'stop_idx': np.int64(10363),\n",
       "  'relative_start_idx': np.int64(4774),\n",
       "  'relative_stop_idx': np.int64(4836)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(10705),\n",
       "  'stop_idx': np.int64(10767),\n",
       "  'relative_start_idx': np.int64(4836),\n",
       "  'relative_stop_idx': np.int64(4898)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(10798),\n",
       "  'stop_idx': np.int64(10860),\n",
       "  'relative_start_idx': np.int64(4898),\n",
       "  'relative_stop_idx': np.int64(4960)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(10891),\n",
       "  'stop_idx': np.int64(10954),\n",
       "  'relative_start_idx': np.int64(4960),\n",
       "  'relative_stop_idx': np.int64(5023)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(10986),\n",
       "  'stop_idx': np.int64(11048),\n",
       "  'relative_start_idx': np.int64(5023),\n",
       "  'relative_stop_idx': np.int64(5085)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(11079),\n",
       "  'stop_idx': np.int64(11141),\n",
       "  'relative_start_idx': np.int64(5085),\n",
       "  'relative_stop_idx': np.int64(5147)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(11172),\n",
       "  'stop_idx': np.int64(11235),\n",
       "  'relative_start_idx': np.int64(5147),\n",
       "  'relative_stop_idx': np.int64(5210)},\n",
       " {'gesture_id': 'dof_12_neg',\n",
       "  'start_idx': np.int64(11265),\n",
       "  'stop_idx': np.int64(11328),\n",
       "  'relative_start_idx': np.int64(5210),\n",
       "  'relative_stop_idx': np.int64(5273)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trials_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python (Neural Feature Identification Pipeline))",
   "language": "python",
   "name": "neural-feature-identification-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
