{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8a132b-f8b3-4d38-9b89-d33c19fe2891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27dffad1-3715-4164-9e23-e3639b151f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-21 17:36:54.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /uufs/chpc.utah.edu/common/home/u1424875/research-projects/neural-feature-identification-pipeline/src\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/u1424875/research-projects/neural-feature-identification-pipeline/.venv/bin/python3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('vegafusion')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt # for vis code\n",
    "import numpy as np # for vis code\n",
    "import polars as pl # for vis code\n",
    "import random # for vis code\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from neural_feature_identification.dataset_utils import load_project_config, load_session_data, generate_train_test_split, print_data_shape, enforce_samples_as_rows\n",
    "from neural_feature_identification.vis_utils import make_tidy_norm, make_kinematics_line_plot, make_events_raster_plot, make_features_line_plot\n",
    "from pathlib import Path\n",
    "\n",
    "print(sys.executable)\n",
    "alt.data_transformers.enable(\"vegafusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76941de9-1e87-49ef-9b54-8a18145f3ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading session data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events: <class 'dict'>\n",
      "\ttrial_start_idxs: <class 'numpy.ndarray'>, (1, 140)\n",
      "\ttrial_stop_idxs: <class 'numpy.ndarray'>, (1, 140)\n",
      "kinematics: <class 'dict'>\n",
      "\tkinematics: <class 'numpy.ndarray'>, (12, 13586)\n",
      "\tnip_time: <class 'numpy.ndarray'>, (1, 13586)\n",
      "nfr: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (192, 13586)\n",
      "sbp-raw: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (192, 13586)\n",
      "dwt-db4: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (1920, 13586)\n",
      "mav: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (192, 13586)\n",
      "events: <class 'dict'>\n",
      "\ttrial_start_idxs: <class 'numpy.ndarray'>, (140, 1)\n",
      "\ttrial_stop_idxs: <class 'numpy.ndarray'>, (140, 1)\n",
      "kinematics: <class 'dict'>\n",
      "\tkinematics: <class 'numpy.ndarray'>, (13586, 12)\n",
      "\tnip_time: <class 'numpy.ndarray'>, (13586, 1)\n",
      "nfr: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (13586, 192)\n",
      "sbp-raw: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (13586, 192)\n",
      "dwt-db4: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (13586, 1920)\n",
      "mav: <class 'dict'>\n",
      "\tfeatures: <class 'numpy.ndarray'>, (13586, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "project_config = load_project_config(Path(\"../config.yaml\"))\n",
    "session_id = \"75\"\n",
    "session_dirpath = Path(project_config['paths']['scratch_root']) / session_id # Path(\"C:/Users/f0397/Desktop/75\")\n",
    "session_data = load_session_data(session_dirpath, project_config)\n",
    "enforce_samples_as_rows(session_data)\n",
    "print_data_shape(session_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1ad5fd-2097-4338-86a1-fbd47cea9219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13586, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinematics_data = session_data['kinematics']['kinematics']\n",
    "kinematics_timestamps = session_data['kinematics']['nip_time']\n",
    "start_timestamps = session_data['events']['trial_start_idxs']\n",
    "stop_timestamps = session_data['events']['trial_stop_idxs']\n",
    "split_params = project_config['analysis']['train_test_split']\n",
    "kinematics_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409e6bd5-7967-4ca7-8fca-7f14df5a55fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-21 17:37:11.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1m---Generating training and test sets---\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mConverting trial timestamps to array indices...\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mFound 140 valid trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mIgnoring combined movements. Processing 120 trials...\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mGesture representations:\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_1_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_2_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_3_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_1_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_2_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_3_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_6_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_6_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_10_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_10_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_12_pos: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m- dof_12_neg: 10 trials\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mSplitting with 'train_first' config and 0.7 train ratio...\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_1_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_2_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_3_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_1_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_2_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_3_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_6_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_6_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_10_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_10_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_12_pos: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m- dof_12_neg: 7 train, 3 test\u001b[0m\n",
      "\u001b[32m2025-10-21 17:37:11.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mneural_feature_identification.dataset_utils\u001b[0m:\u001b[36mgenerate_train_test_split\u001b[0m:\u001b[36m217\u001b[0m - \u001b[1m---Split Complete---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_idxs, test_idxs, train_trials_info, test_trials_info =  generate_train_test_split(\n",
    "    kinematics=kinematics_data,\n",
    "    kinematics_timestamps=kinematics_timestamps,\n",
    "    trial_start_timestamps=start_timestamps,\n",
    "    trial_stop_timestamps=stop_timestamps,\n",
    "    train_ratio=split_params['train_ratio'],\n",
    "    training_type=split_params['split_type'],\n",
    "    include_combined=split_params['include_combined'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127a1acc-222b-477e-82d1-7f70c66c144e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 13586 timestamps\n",
      "Resampling data by averaging over 20384.84 timestamp units\n",
      "Resampled data has 661 timestamps\n"
     ]
    }
   ],
   "source": [
    "vis_df = make_tidy_norm(session_data, project_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78a1c38-d9f1-4ea7-a26f-fc22644b1be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "outputs": [],
   "source": [
    "x_domain = [vis_df['timestamps'].min(), vis_df['timestamps'].max()]\n",
    "\n",
    "start_stamps = session_data.get('events', {}).get('trial_start_idxs', np.array([]))\n",
    "stop_stamps = session_data.get('events', {}).get('trial_stop_idxs', np.array([]))\n",
    "\n",
    "random.seed(42)\n",
    "selected_channels_map = {}\n",
    "dwt_subsample_count = project_config['vis']['dwt_subsample_count']\n",
    "dwt_df = vis_df.filter(pl.col('feature_type') == 'DWT-DB4')\n",
    "dwt_channels_all = dwt_df.get_column('feature_id').unique().to_list()\n",
    "if len(dwt_channels_all) > dwt_subsample_count:\n",
    "    selected_channels_map['dwt-db4'] = random.sample(dwt_channels_all, dwt_subsample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73766ae9-b9dc-46a5-87a6-310ba36eb4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_kinematics = make_kinematics_line_plot(vis_df, project_config, x_domain=x_domain)\n",
    "plt_events = make_events_raster_plot(start_stamps, stop_stamps, x_domain=x_domain)\n",
    "plt_features = []\n",
    "for f_name in project_config['analysis']['feature_sets']:\n",
    "    feature_key = f_name.lower()\n",
    "    selected_channels = selected_channels_map.get(feature_key)\n",
    "    plt = make_features_line_plot(vis_df, f_name, selected_channels, x_domain=x_domain)\n",
    "    plt_features.append(plt)\n",
    "final_chart = alt.vconcat(\n",
    "    plt_kinematics,\n",
    "    plt_events,\n",
    "    *plt_features,\n",
    ").resolve_scale(\n",
    "    color='independent',\n",
    ").properties(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28bbbfb-a3bf-49bd-ad47-ca8748bc986a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The \"vegafusion\" data transformer and chart.transformed_data feature requires\nversion 1.5.0 or greater of the 'vegafusion-python-embed' and 'vegafusion' packages.\nThese can be installed with pip using:\n    pip install \"vegafusion[embed]>=1.5.0\"\nOr with conda using:\n    conda install -c conda-forge \"vegafusion-python-embed>=1.5.0\" \"vegafusion>=1.5.0\"\n\nImportError: No module named 'vegafusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/_importers.py:15\u001b[39m, in \u001b[36mimport_vegafusion\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvegafusion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvf\u001b[39;00m\n\u001b[32m     17\u001b[39m     version = importlib_version(\u001b[33m\"\u001b[39m\u001b[33mvegafusion\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'vegafusion'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfinal_chart\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabeled_features_vis-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/vegalite/v5/api.py:2289\u001b[39m, in \u001b[36mTopLevelMixin.save\u001b[39m\u001b[34m(self, fp, format, override_data_transformer, scale_factor, mode, vegalite_version, vega_version, vegaembed_version, embed_options, json_kwds, engine, inline, **kwargs)\u001b[39m\n\u001b[32m   2287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m override_data_transformer:\n\u001b[32m   2288\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m data_transformers.disable_max_rows():\n\u001b[32m-> \u001b[39m\u001b[32m2289\u001b[39m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2290\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2291\u001b[39m     save(**kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/save.py:216\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(chart, fp, vega_version, vegaembed_version, format, mode, vegalite_version, embed_options, json_kwds, scale_factor, engine, inline, **kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_vegafusion():\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# When the vegafusion data transformer is enabled, transforms will be\u001b[39;00m\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# evaluated during save and the resulting data will be included in the\u001b[39;00m\n\u001b[32m    214\u001b[39m     \u001b[38;5;66;03m# vega specification that is saved.\u001b[39;00m\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m data_transformers.disable_max_rows():\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[43mperform_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# Temporarily turn off any data transformers so that all data is inlined\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# when calling chart.to_dict. This is relevant for vl-convert which cannot access\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# local json files which could be created by a json data transformer. Furthermore,\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# we don't exit the with statement until this function completed due to the issue\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# described at https://github.com/vega/vl-convert/issues/31\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m data_transformers.enable(\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m), data_transformers.disable_max_rows():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/save.py:160\u001b[39m, in \u001b[36msave.<locals>.perform_save\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inline:\n\u001b[32m    159\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mtemplate\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33minline\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     mb_html = \u001b[43mspec_to_mimebundle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvega_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvega_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvegalite_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvegalite_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvegaembed_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvegaembed_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson_kwds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     write_file_or_filename(\n\u001b[32m    172\u001b[39m         fp, mb_html[\u001b[33m\"\u001b[39m\u001b[33mtext/html\u001b[39m\u001b[33m\"\u001b[39m], mode=\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=encoding\n\u001b[32m    173\u001b[39m     )\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpng\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/mimebundle.py:129\u001b[39m, in \u001b[36mspec_to_mimebundle\u001b[39m\u001b[34m(spec, format, mode, vega_version, vegaembed_version, vegalite_version, embed_options, engine, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m internal_mode: Literal[\u001b[33m\"\u001b[39m\u001b[33mvega-lite\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvega\u001b[39m\u001b[33m\"\u001b[39m] = mode\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_vegafusion():\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     spec = \u001b[43mcompile_with_vegafusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     internal_mode = \u001b[33m\"\u001b[39m\u001b[33mvega\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Default to the embed options set by alt.renderers.set_embed_options\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/_vegafusion_data.py:258\u001b[39m, in \u001b[36mcompile_with_vegafusion\u001b[39m\u001b[34m(vegalite_spec)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# Local import to avoid circular ImportError\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maltair\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_transformers, vegalite_compilers\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m vf = \u001b[43mimport_vegafusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# Compile Vega-Lite spec to Vega\u001b[39;00m\n\u001b[32m    261\u001b[39m compiler = vegalite_compilers.get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/research-projects/neural-feature-identification-pipeline/.venv/lib/python3.13/site-packages/altair/utils/_importers.py:44\u001b[39m, in \u001b[36mimport_vegafusion\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     34\u001b[39m     msg = (\n\u001b[32m     35\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvegafusion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m data transformer and chart.transformed_data feature requires\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mversion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or greater of the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvegafusion-python-embed\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvegafusion\u001b[39m\u001b[33m'\u001b[39m\u001b[33m packages.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImportError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr.args[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: The \"vegafusion\" data transformer and chart.transformed_data feature requires\nversion 1.5.0 or greater of the 'vegafusion-python-embed' and 'vegafusion' packages.\nThese can be installed with pip using:\n    pip install \"vegafusion[embed]>=1.5.0\"\nOr with conda using:\n    conda install -c conda-forge \"vegafusion-python-embed>=1.5.0\" \"vegafusion>=1.5.0\"\n\nImportError: No module named 'vegafusion'"
     ]
    }
   ],
   "source": [
    "final_chart.save(f\"labeled_features_vis-{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python (Neural Feature Identification Pipeline))",
   "language": "python",
   "name": "neural-feature-identification-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
