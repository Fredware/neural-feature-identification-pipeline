{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:06.403326Z",
     "start_time": "2025-10-20T14:26:01.824160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import altair as alt\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from neural_feature_identification.dataset_utils import generate_train_test_split\n",
    "\n",
    "print(sys.executable)\n",
    "alt.data_transformers.enable(\"vegafusion\")"
   ],
   "id": "92d107c28ba77e13",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-20 08:26:06.342\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\f0397\\Box\\NeuroRoboticsLab\\JAGLAB\\Projects\\Neural Features\\chpc-code\\src\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f0397\\miniforge3\\envs\\neural-feature-identification-pipeline\\python.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('vegafusion')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:16.062801Z",
     "start_time": "2025-10-20T14:26:16.059004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_project_config(config_path: Path) -> dict:\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ],
   "id": "af729026f7aefd5e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:17.697293Z",
     "start_time": "2025-10-20T14:26:17.691928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_hdf_datasets(filepath: Path, keys: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Reads specified datasets from a single HDF5 file.\n",
    "    :param filepath:\n",
    "    :param keys:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"Warning File not found at {filepath}. Skipping.\")\n",
    "        return {}\n",
    "\n",
    "    data = {}\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        for key in keys:\n",
    "            if key in f:\n",
    "                data[key] = f[key][:]\n",
    "            else:\n",
    "                print(f\"Warning. Key '{key}' not found in {filepath.name}.\")\n",
    "    return data"
   ],
   "id": "e57a9efbd8df5000",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:19.899899Z",
     "start_time": "2025-10-20T14:26:19.885778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tidy_and_transform_data(session_data: dict, project_config: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Structures the data into a tidy, long-format DataFrame for VIS with Altair.\n",
    "    Transforms the data for VIS by downsampling and applying a normalization transformation to each channel.\n",
    "    :param project_config:\n",
    "    :param session_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Create initial nested DataFrame\n",
    "    df_constructor = {\n",
    "        'timestamps': all_data['kinematics']['nip_time'].T,\n",
    "        'kinematics': all_data['kinematics']['kinematics'].T,\n",
    "    }\n",
    "    feature_names = project_config['analysis']['feature_sets']\n",
    "    for name in feature_names:\n",
    "        key_name = name.lower()\n",
    "        if 'features' in session_data.get(key_name, {}):\n",
    "            df_constructor[name] = session_data[key_name]['features'].T\n",
    "    nested_df = pl.DataFrame(df_constructor)\n",
    "\n",
    "    # Flatten timestamp column\n",
    "    flat_df = nested_df.explode('timestamps')\n",
    "\n",
    "    # Dynamically create expression to unnest each array column into individual columns\n",
    "    unnested_expressions = []\n",
    "    for name in ['kinematics'] + feature_names:\n",
    "        col_name = name if name != 'kinematics' else 'kinematics'\n",
    "        if col_name in flat_df.columns:\n",
    "            list_len = flat_df.select(pl.col(col_name).arr.len().first()).item()\n",
    "            if list_len is not None:\n",
    "                unnested_expressions.extend(\n",
    "                    [pl.col(col_name).arr.get(i).alias(f\"{name}_{i+1}\") for i in range(list_len)]\n",
    "                )\n",
    "\n",
    "    # Build the wide DataFrame by applying the unnesting expressions\n",
    "    wide_df = flat_df.select(\n",
    "        pl.col('timestamps'),\n",
    "        *unnested_expressions\n",
    "    )\n",
    "\n",
    "    # Aggregate/downsample data to prevent browser memory issues\n",
    "    print(f\"Original data has {len(wide_df)} timestamps\")\n",
    "    plt_point_count = project_config['vis']['num_of_x_points']\n",
    "    time_range = wide_df['timestamps'].max() - wide_df['timestamps'].min()\n",
    "    resampling_interval = time_range / plt_point_count\n",
    "    if resampling_interval < 1: resampling_interval = 1\n",
    "    print(f\"Resampling data by averaging over {resampling_interval:0.2f} timestamp units\")\n",
    "    wide_df_resampled = wide_df.group_by(\n",
    "        (pl.col(\"timestamps\") // resampling_interval).alias(\"time_bin\")\n",
    "    ).agg(pl.all().mean()).drop(\"time_bin\")\n",
    "    print(f\"Resampled data has {len(wide_df_resampled)} timestamps\")\n",
    "\n",
    "    # Melt (wide2long/unpivot transform) the wide DataFrame into a long, tidy format\n",
    "    tidy_df = wide_df_resampled.unpivot(index=['timestamps'], variable_name='feature_id', value_name='value')\n",
    "\n",
    "    # Add a column for easy filtering ('feature_type': 'kinematics', 'nfr', ...)\n",
    "    tidy_df = tidy_df.with_columns(\n",
    "        pl.col('feature_id').str.split_exact(by='_', n=1).struct.field('field_0').alias('feature_type')\n",
    "    )\n",
    "\n",
    "    # Channel by channel normalization to improve heatmap visibility\n",
    "    kinematics_df  = tidy_df.filter(pl.col('feature_type') == 'kinematics')\n",
    "    features_df = tidy_df.filter(pl.col('feature_type') != 'kinematics')\n",
    "    features_df_normalized = features_df.with_columns(\n",
    "        min_val=pl.min('value').over('feature_id'),\n",
    "        max_val=pl.max('value').over('feature_id')\n",
    "    ).with_columns(\n",
    "        range_val=(pl.col('max_val') - pl.col('min_val'))\n",
    "    ).with_columns(\n",
    "        norm_val=pl.when(pl.col('range_val')>0)\n",
    "                 .then((pl.col('value') - pl.col('min_val')) / pl.col('range_val'))\n",
    "                 .otherwise(0.0)\n",
    "    ).with_columns(\n",
    "        value=(pl.col('norm_val') * pl.col('max_val').sqrt()).fill_nan(0)\n",
    "    ).drop('min_val', 'max_val', 'range_val', 'norm_val')\n",
    "    tidy_df_transformed = pl.concat([kinematics_df, features_df_normalized])\n",
    "\n",
    "    return tidy_df_transformed"
   ],
   "id": "5a5bf042fed41503",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:22.396115Z",
     "start_time": "2025-10-20T14:26:22.389151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_kinematics_plot(plt_df: pl.DataFrame, project_config: dict, x_domain: list) -> alt.Chart():\n",
    "    \"\"\"\n",
    "    Creates a stacked line chart of the kinematic labels\n",
    "    :param plt_df:\n",
    "    :param project_config:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    kinematics_df = plt_df.filter(pl.col('feature_type') == 'kinematics')\n",
    "    plt_offset = project_config['vis']['kinematics_offset']\n",
    "    kinematics_df_offset = kinematics_df.with_columns(\n",
    "        pl.col('feature_id').str.split_exact(by='_', n=1).struct.field('field_1').cast(pl.Int32).alias('dof_id')\n",
    "    ).with_columns(\n",
    "        (pl.col('value') + (pl.col('dof_id')*plt_offset)).alias('plot_value')\n",
    "    )\n",
    "    plt_kinematics =  alt.Chart(kinematics_df_offset).mark_line().encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        y=alt.Y('plot_value:Q', title='Kinematic Position (Offset)', axis=alt.Axis(labels=False, ticks=False, grid=False)),\n",
    "        color=alt.Color('feature_id:N', title=\"DOF ID\", sort=alt.EncodingSortField(field='dof_id', order='descending')),\n",
    "    ).properties(\n",
    "        width=1800,\n",
    "        height=360,\n",
    "    )\n",
    "\n",
    "    return plt_kinematics\n",
    "\n",
    "def make_event_markers_plot(trial_start_stamps: np.ndarray, trial_stop_stamps: np.ndarray, x_domain: list) -> alt.Chart():\n",
    "    starts_df = pl.DataFrame({'timestamp': trial_start_stamps.flatten(), 'event': 'start'})\n",
    "    stops_df = pl.DataFrame({'timestamp': trial_stop_stamps.flatten(), 'event': 'stop'})\n",
    "    events_df = pl.concat([starts_df, stops_df])\n",
    "    plt_event_markers = alt.Chart(events_df).mark_rule(strokeDash=[4, 4], size=2).encode(\n",
    "        x=alt.X('timestamp:Q', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        color=alt.Color(\n",
    "            'event:N',\n",
    "            scale=alt.Scale(domain=['start', 'stop'], range=['green', 'red']),\n",
    "        )\n",
    "    ).properties(\n",
    "        width=1800,\n",
    "        height=36,\n",
    "    )\n",
    "\n",
    "\n",
    "    return plt_event_markers"
   ],
   "id": "60ce4b9bcb8395e1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:26:24.702180Z",
     "start_time": "2025-10-20T14:26:24.694855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_features_heatmap(plt_df: pl.DataFrame, feature_type: str, color_scheme: str, selected_chans: list[str] = None) -> alt.Chart:\n",
    "    feature_data = plt_df.filter(pl.col('feature_type') == feature_type)\n",
    "\n",
    "    if selected_chans:\n",
    "        feature_data = feature_data.filter(pl.col('feature_id').is_in(selected_chans))\n",
    "\n",
    "    return alt.Chart(feature_data).mark_rect().encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y('feature_id:O', title='Feature Index', sort=None, axis=alt.Axis(labels=False, ticks=False)),\n",
    "        detail='feature_id:N',\n",
    "    ).properties(\n",
    "        title=f'{feature_type.upper()} Features Vs NIP Time',\n",
    "        width=1800,\n",
    "        height=720\n",
    "    )\n",
    "\n",
    "def make_feature_line_plot(plt_df: pl.DataFrame, feature_type: str, selected_channels: list[str] = None, x_domain: list = None) -> alt.Chart:\n",
    "    \"\"\"\n",
    "    Create a line chart for a given feature set with superimposed, transparent channels\n",
    "    :param plt_df:\n",
    "    :param feature_type:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature_data = plt_df.filter(pl.col('feature_type') == feature_type)\n",
    "\n",
    "    # Apply subsampling if a list of selected channels is provided. Intended for the DWT feature set\n",
    "    if selected_channels:\n",
    "        feature_data = feature_data.filter(pl.col('feature_id').is_in(selected_channels))\n",
    "\n",
    "    return alt.Chart(feature_data).mark_line(opacity=0.12).encode(\n",
    "        x=alt.X('timestamps:Q', title='Time (NIP Units)', scale=alt.Scale(zero=False, domain=x_domain)),\n",
    "        y=alt.Y('value:Q', title=f'{feature_type.upper()} Normalized Activation', axis=alt.Axis(labels=False, ticks=False,grid=False)),\n",
    "        detail='feature_id:N',\n",
    "    ).properties(width=1800, height=360)\n"
   ],
   "id": "1a44973377246c8f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:21.384073Z",
     "start_time": "2025-10-20T14:36:21.275950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#def main():\n",
    "config = load_project_config(Path(\"../config.yaml\"))\n",
    "BASE_DIR = Path(\"C:/Users/f0397/Desktop/75\")\n",
    "\n",
    "files_to_load = {\n",
    "    'events': {'path': BASE_DIR / \"events.h5\", 'keys': ['trial_start_idxs', 'trial_stop_idxs']},\n",
    "    'kinematics': {'path': BASE_DIR / \"kinematics.h5\", 'keys': ['kinematics', 'nip_time']},\n",
    "}\n",
    "for feature_name in config['analysis']['feature_sets']:\n",
    "    key_name = feature_name.lower()\n",
    "    files_to_load[key_name] = {'path': BASE_DIR / \"features\" / f\"{feature_name}.h5\", 'keys': ['features']}\n",
    "\n",
    "all_data = {}\n",
    "for name, details in tqdm(files_to_load.items(), desc='Loading data files'):\n",
    "    all_data[name] = read_hdf_datasets(details['path'], details['keys'])"
   ],
   "id": "862319135938c293",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data files: 100%|██████████| 6/6 [00:00<00:00, 65.64it/s]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:27:31.365404Z",
     "start_time": "2025-10-20T14:27:31.358750Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c180b4ceb44992ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trial_start_idxs': array([[32007776., 32100844., 32193880., 32285964., 32378028., 32471084.,\n",
       "         32563148., 32655216., 32748272., 32840356., 32962136., 33055188.,\n",
       "         33147262., 33240324., 33332396., 33425444., 33516520., 33609584.,\n",
       "         33701640., 33794724., 33918440., 34010536., 34103592., 34195652.,\n",
       "         34287716., 34380792., 34472844., 34564940., 34657964., 34750064.,\n",
       "         34872820., 34964880., 35056940., 35149992., 35242064., 35334128.,\n",
       "         35427192., 35519264., 35612340., 35705404., 35828132., 35920224.,\n",
       "         36013260., 36105340., 36197408., 36290488., 36382544., 36474604.,\n",
       "         36567680., 36659744., 36781496., 36880500., 36978512., 37077528.,\n",
       "         37175528., 37273528., 37372536., 37472512., 37571520., 37669528.,\n",
       "         37798216., 37890308., 37983352., 38075408., 38168496., 38260548.,\n",
       "         38352616., 38444700., 38537760., 38629820., 38752584., 38844640.,\n",
       "         38936704., 39029780., 39121860., 39214904., 39307968., 39400036.,\n",
       "         39493104., 39585156., 39707924., 39799984., 39892048., 39985124.,\n",
       "         40077200., 40169260., 40262312., 40354384., 40447444., 40539496.,\n",
       "         40661296., 40754348., 40846416., 40938468., 41032524., 41125576.,\n",
       "         41217640., 41309736., 41402764., 41494864., 41617616., 41709680.,\n",
       "         41802740., 41894796., 41986884., 42079940., 42172012., 42265056.,\n",
       "         42357136., 42449192., 42571960., 42664020., 42756084., 42850136.,\n",
       "         42942200., 43034292., 43126360., 43219408., 43312472., 43403552.,\n",
       "         43526324., 43620364., 43715392., 43809460., 43903500., 43997544.,\n",
       "         44091600., 44185640., 44280684., 44374736., 44499488., 44592536.,\n",
       "         44689568., 44783604., 44877644., 44971692., 45065744., 45159796.,\n",
       "         45253836., 45347900.]]),\n",
       " 'trial_stop_idxs': array([[32070136., 32163190., 32255264., 32347336., 32440408., 32532478.,\n",
       "         32624544., 32716610., 32809674., 32901742., 33024484., 33116568.,\n",
       "         33208634., 33301684., 33393752., 33485820., 33578888., 33670952.,\n",
       "         33763028., 33857088., 33979840., 34072888., 34164960., 34258036.,\n",
       "         34350104., 34442172., 34534232., 34626308., 34719360., 34811424.,\n",
       "         34934192., 35026244., 35118344., 35211388., 35304456., 35395528.,\n",
       "         35488592., 35580652., 35674700., 35766776., 35889536., 35981600.,\n",
       "         36074652., 36166732., 36258792., 36351852., 36443920., 36535992.,\n",
       "         36629048., 36721112., 36849832., 36947808., 37045824., 37144832.,\n",
       "         37242836., 37342828., 37440840., 37540844., 37638828., 37737840.,\n",
       "         37859608., 37951672., 38044728., 38136812., 38229856., 38321924.,\n",
       "         38415000., 38507060., 38599128., 38691212., 38813944., 38906040.,\n",
       "         38999092., 39091152., 39183216., 39277280., 39369336., 39462408.,\n",
       "         39554464., 39646528., 39769312., 39862340., 39953440., 40046500.,\n",
       "         40138560., 40230632., 40323676., 40415752., 40508800., 40600888.,\n",
       "         40723648., 40815728., 40907784., 41000840., 41093888., 41186972.,\n",
       "         41279048., 41372096., 41464168., 41556224., 41678992., 41772040.,\n",
       "         41864104., 41956192., 42049248., 42141308., 42233368., 42325444.,\n",
       "         42418496., 42510572., 42633324., 42725420., 42818476., 42911532.,\n",
       "         43003596., 43096648., 43188712., 43280780., 43372876., 43465920.,\n",
       "         43589664., 43683704., 43778768., 43872800., 43966844., 44060908.,\n",
       "         44154948., 44249012., 44344040., 44438092., 44561840., 44656888.,\n",
       "         44751916., 44846948., 44940988., 45035044., 45129092., 45223144.,\n",
       "         45317212., 45412240.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 13586 timestamps\n",
      "Resampling data by averaging over 20384.84 timestamp units\n",
      "Resampled data has 661 timestamps\n",
      "shape: (5,)\n",
      "Series: 'feature_type' [str]\n",
      "[\n",
      "\t\"DWT-DB4\"\n",
      "\t\"kinematics\"\n",
      "\t\"NFR\"\n",
      "\t\"SBP-RAW\"\n",
      "\t\"MAV\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (1_657_788, 4)\n",
       "┌─────────────┬──────────────┬──────────┬──────────────┐\n",
       "│ timestamps  ┆ feature_id   ┆ value    ┆ feature_type │\n",
       "│ ---         ┆ ---          ┆ ---      ┆ ---          │\n",
       "│ f64         ┆ str          ┆ f64      ┆ str          │\n",
       "╞═════════════╪══════════════╪══════════╪══════════════╡\n",
       "│ 4.1452e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 4.1004e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 4.3002e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 3.7029e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ 3.9720e7    ┆ kinematics_1 ┆ 0.0      ┆ kinematics   │\n",
       "│ …           ┆ …            ┆ …        ┆ …            │\n",
       "│ 4.2227444e7 ┆ MAV_192      ┆ 0.471449 ┆ MAV          │\n",
       "│ 3.2728e7    ┆ MAV_192      ┆ 0.305229 ┆ MAV          │\n",
       "│ 3.8436e7    ┆ MAV_192      ┆ 0.363485 ┆ MAV          │\n",
       "│ 4.3124e7    ┆ MAV_192      ┆ 0.46972  ┆ MAV          │\n",
       "│ 3.4521853e7 ┆ MAV_192      ┆ 0.237767 ┆ MAV          │\n",
       "└─────────────┴──────────────┴──────────┴──────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_657_788, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamps</th><th>feature_id</th><th>value</th><th>feature_type</th></tr><tr><td>f64</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>4.1452e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>4.1004e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>4.3002e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>3.7029e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>3.9720e7</td><td>&quot;kinematics_1&quot;</td><td>0.0</td><td>&quot;kinematics&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4.2227444e7</td><td>&quot;MAV_192&quot;</td><td>0.471449</td><td>&quot;MAV&quot;</td></tr><tr><td>3.2728e7</td><td>&quot;MAV_192&quot;</td><td>0.305229</td><td>&quot;MAV&quot;</td></tr><tr><td>3.8436e7</td><td>&quot;MAV_192&quot;</td><td>0.363485</td><td>&quot;MAV&quot;</td></tr><tr><td>4.3124e7</td><td>&quot;MAV_192&quot;</td><td>0.46972</td><td>&quot;MAV&quot;</td></tr><tr><td>3.4521853e7</td><td>&quot;MAV_192&quot;</td><td>0.237767</td><td>&quot;MAV&quot;</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23,
   "source": [
    "tidy_df = tidy_and_transform_data(all_data, config)\n",
    "print(tidy_df['feature_type'].unique())\n",
    "tidy_df"
   ],
   "id": "257c4819fb4d590b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.517122Z",
     "start_time": "2025-10-20T03:58:24.480252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "selected_channels_map = {}\n",
    "dwt_subsample_count = config['vis']['dwt_subsample_count']\n",
    "dwt_df = tidy_df.filter(pl.col('feature_type') == 'DWT-DB4')\n",
    "all_dwt_channels = dwt_df.get_column('feature_id').unique().to_list()\n",
    "if len(all_dwt_channels) > dwt_subsample_count:\n",
    "    selected_channels_map['dwt-db4'] = random.sample(all_dwt_channels, dwt_subsample_count)"
   ],
   "id": "2eee72225b64c99d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.527582Z",
     "start_time": "2025-10-20T03:58:24.523071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_stamps = all_data.get('events', {}).get('trial_start_idxs', np.array([]))\n",
    "stop_stamps = all_data.get('events', {}).get('trial_stop_idxs', np.array([]))"
   ],
   "id": "b3002e213bee035",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.546174Z",
     "start_time": "2025-10-20T03:58:24.537716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_domain = [tidy_df['timestamps'].min(), tidy_df['timestamps'].max()]\n",
    "x_domain"
   ],
   "id": "79ba2d236acbac9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31978596.6, 45423141.45454545]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.631839Z",
     "start_time": "2025-10-20T03:58:24.577293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt_kinematics = make_kinematics_plot(tidy_df, config, x_domain=x_domain)\n",
    "plt_events = make_event_markers_plot(start_stamps, stop_stamps, x_domain=x_domain)\n",
    "plt_features = []\n",
    "for f_name in config['analysis']['feature_sets']:\n",
    "    feature_key = f_name.lower()\n",
    "    selected_channels = selected_channels_map.get(feature_key)\n",
    "    plt = make_feature_line_plot(tidy_df, f_name, selected_channels, x_domain=x_domain)\n",
    "    plt_features.append(plt)"
   ],
   "id": "dac3d8dd84a89c4e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T03:58:24.648890Z",
     "start_time": "2025-10-20T03:58:24.639106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_chart = alt.vconcat(\n",
    "    plt_kinematics,\n",
    "    plt_events,\n",
    "    *plt_features,\n",
    ").resolve_scale(\n",
    "    color='independent',\n",
    ").properties(\n",
    ")"
   ],
   "id": "7b411a7c7f0d7aaf",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_chart.save(\"session_vis.html\")",
   "id": "925074c31d3996a2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:26.734685Z",
     "start_time": "2025-10-20T14:36:26.730158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kinematics_data = all_data['kinematics']['kinematics']\n",
    "timestamps_vec = all_data['kinematics']['nip_time']\n",
    "start_stamps = all_data['events']['trial_start_idxs']\n",
    "stop_stamps = all_data['events']['trial_stop_idxs']\n",
    "\n",
    "split_params = config['analysis']['train_test_split']"
   ],
   "id": "82921c1263d15da9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T14:36:37.028246Z",
     "start_time": "2025-10-20T14:36:37.022141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_idxs, test_idxs, train_trials_info, test_trials_info =  generate_train_test_split(\n",
    "    kinematics=kinematics_data,\n",
    "    kinematics_timestamps=timestamps_vec,\n",
    "    trial_start_timestamps=start_stamps,\n",
    "    trial_stop_timestamps=stop_stamps,\n",
    "    train_ratio=split_params['train_ratio'],\n",
    "    training_type=split_params['split_type'],\n",
    "    include_combined=split_params['include_combined'],\n",
    ")"
   ],
   "id": "73b7c6a876222b7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-20 08:36:37.024\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m79\u001B[0m - \u001B[1m---Generating training and test sets---\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m85\u001B[0m - \u001B[1mConverting trial timestamps to array indices...\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m102\u001B[0m - \u001B[1mFound 0 valid trials\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m136\u001B[0m - \u001B[1mIgnoring combined movements. Processing 0 trials...\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m145\u001B[0m - \u001B[1mGesture representations:\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m151\u001B[0m - \u001B[1mSplitting with 'train_first' config and 0.7 train ratio...\u001B[0m\n",
      "\u001B[32m2025-10-20 08:36:37.025\u001B[0m | \u001B[33m\u001B[1mWARNING \u001B[0m | \u001B[36mneural_feature_identification.dataset_utils\u001B[0m:\u001B[36mgenerate_train_test_split\u001B[0m:\u001B[36m170\u001B[0m - \u001B[33m\u001B[1mNo training trials found. Returning empty arrays\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Neural Features Pipeline)",
   "language": "python",
   "name": "neural-feature-identification-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
